{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Graph utilities.\"\"\"\n",
    "\n",
    "# from time import time\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "__author__ = \"Zhang Zhengyan\"\n",
    "__email__ = \"zhangzhengyan14@mails.tsinghua.edu.cn\"\n",
    "\n",
    "\n",
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.G = None\n",
    "        self.look_up_dict = {}\n",
    "        self.look_back_list = []\n",
    "        self.node_size = 0\n",
    "\n",
    "    def encode_node(self):\n",
    "        look_up = self.look_up_dict\n",
    "        look_back = self.look_back_list\n",
    "        \n",
    "        for node in self.G.nodes():\n",
    "            look_up[node] = self.node_size\n",
    "            look_back.append(node)\n",
    "            self.node_size += 1\n",
    "            self.G.nodes[node]['status'] = ''\n",
    "\n",
    "    def read_g(self, g):\n",
    "        self.G = g\n",
    "        self.encode_node()\n",
    "\n",
    "    def read_adjlist(self, filename):\n",
    "        \"\"\" Read graph from adjacency file in which the edge must be unweighted\n",
    "            the format of each line: v1 n1 n2 n3 ... nk\n",
    "            :param filename: the filename of input file\n",
    "        \"\"\"\n",
    "        self.G = nx.read_adjlist(filename, create_using=nx.DiGraph())\n",
    "       \n",
    "        for i, j in self.G.edges():\n",
    "            self.G[i][j]['weight'] = 1.0\n",
    "        self.encode_node()\n",
    "\n",
    "    def read_edgelist(self, filename, weighted=False, directed=False):\n",
    "        self.G = nx.DiGraph()\n",
    "\n",
    "        if directed:\n",
    "            def read_unweighted(l):\n",
    "                src, dst = l.split()\n",
    "                self.G.add_edge(src, dst)\n",
    "                self.G[src][dst]['weight'] = 1.0\n",
    "\n",
    "            def read_weighted(l):\n",
    "                src, dst, w = l.split()\n",
    "                self.G.add_edge(src, dst)\n",
    "                self.G[src][dst]['weight'] = float(w)\n",
    "        else:\n",
    "            def read_unweighted(l):\n",
    "                src, dst = l.split()\n",
    "                self.G.add_edge(src, dst)\n",
    "                self.G.add_edge(dst, src)\n",
    "                self.G[src][dst]['weight'] = 1.0\n",
    "                self.G[dst][src]['weight'] = 1.0\n",
    "\n",
    "            def read_weighted(l):\n",
    "                src, dst, w = l.split()\n",
    "                self.G.add_edge(src, dst)\n",
    "                self.G.add_edge(dst, src)\n",
    "                self.G[src][dst]['weight'] = float(w)\n",
    "                self.G[dst][src]['weight'] = float(w)\n",
    "        fin = open(filename, 'r')\n",
    "        func = read_unweighted\n",
    "        if weighted:\n",
    "            func = read_weighted\n",
    "        while 1:\n",
    "            l = fin.readline()\n",
    "            if l == '':\n",
    "                break\n",
    "            func(l)\n",
    "        fin.close()\n",
    "        self.encode_node()\n",
    "\n",
    "    def read_node_label(self, filename):\n",
    "        fin = open(filename, 'r')\n",
    "        while 1:\n",
    "            l = fin.readline()\n",
    "            if l == '':\n",
    "                break\n",
    "            vec = l.split()\n",
    "            self.G.nodes[vec[0]]['label'] = vec[1:]\n",
    "        fin.close()\n",
    "\n",
    "    def read_node_features(self, filename):\n",
    "        fin = open(filename, 'r')\n",
    "        for l in fin.readlines():\n",
    "            vec = l.split()\n",
    "            self.G.nodes[vec[0]]['feature'] = np.array(\n",
    "                [float(x) for x in vec[1:]])\n",
    "        fin.close()\n",
    "\n",
    "    def read_node_status(self, filename):\n",
    "        fin = open(filename, 'r')\n",
    "        while 1:\n",
    "            l = fin.readline()\n",
    "            if l == '':\n",
    "                break\n",
    "            vec = l.split()\n",
    "            self.G.nodes[vec[0]]['status'] = vec[1]  # train test valid\n",
    "        fin.close()\n",
    "\n",
    "    def read_edge_label(self, filename):\n",
    "        fin = open(filename, 'r')\n",
    "        while 1:\n",
    "            l = fin.readline()\n",
    "            if l == '':\n",
    "                break\n",
    "            vec = l.split()\n",
    "            self.G[vec[0]][vec[1]]['label'] = vec[2:]\n",
    "        fin.close()\n",
    "        \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "\n",
    "\n",
    "class TADW(object):\n",
    "\n",
    "    def __init__(self, graph, dim, lamb=0.2):\n",
    "        self.g = graph\n",
    "        self.lamb = lamb\n",
    "        self.dim = int(dim/2)\n",
    "        self.train()\n",
    "\n",
    "    def getAdj(self):\n",
    "        graph = self.g.G\n",
    "        node_size = self.g.node_size\n",
    "        look_up = self.g.look_up_dict\n",
    "        adj = np.zeros((node_size, node_size))\n",
    "        for edge in self.g.G.edges():\n",
    "            adj[look_up[edge[0]]][look_up[edge[1]]] = 1.0\n",
    "            adj[look_up[edge[1]]][look_up[edge[0]]] = 1.0\n",
    "        # ScaleSimMat\n",
    "        return adj/np.sum(adj, axis=1)\n",
    "\n",
    "    def save_embeddings(self, filename):\n",
    "        fout = open(filename, 'w')\n",
    "        node_num = len(self.vectors.keys())\n",
    "        fout.write(\"{} {}\\n\".format(node_num, self.dim*2))\n",
    "        for node, vec in self.vectors.items():\n",
    "            fout.write(\"{} {}\\n\".format(node, ' '.join([x.__str__() for x in vec])))\n",
    "        fout.close()\n",
    "\n",
    "    def getOriginalT(self):\n",
    "        g = self.g.G\n",
    "        look_back = self.g.look_back_list\n",
    "        self.features = np.vstack([g.nodes[look_back[i]]['feature']\n",
    "                                   for i in range(g.number_of_nodes())])\n",
    "        #self.features = self.features / (np.sum(self.features , axis=1)).reshape(len(self.features),1)\n",
    "        return self.features.T\n",
    "    \n",
    "    def getT(self):\n",
    "        g = self.g.G\n",
    "        look_back = self.g.look_back_list\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.features = np.vstack([g.nodes[look_back[i]]['feature']\n",
    "                                   for i in range(g.number_of_nodes())])\n",
    "        self.preprocessFeature()\n",
    "        return self.features.T\n",
    "\n",
    "    def preprocessFeature(self):\n",
    "        if self.features.shape[1] > 50:\n",
    "            U, S, VT = la.svd(self.features)\n",
    "            Ud = U[:, 0:50]\n",
    "            Sd = S[0:50]\n",
    "            self.features = np.array(Ud)*Sd.reshape(50)\n",
    "            \n",
    "    def getM(self):\n",
    "        self.adj = self.getAdj()\n",
    "        return (self.adj + np.dot(self.adj, self.adj ))/2\n",
    "    \n",
    "    def train(self):\n",
    "        self.adj = self.getAdj()\n",
    "        # M=(A+A^2)/2 where A is the row-normalized adjacency matrix\n",
    "        self.M = (self.adj + np.dot(self.adj, self.adj) )/ 2\n",
    "        # T is feature_size*node_num, text features\n",
    "        self.T = self.getT()\n",
    "        self.node_size = self.adj.shape[0]\n",
    "        self.feature_size = self.features.shape[1]\n",
    "        self.W = np.random.randn(self.dim, self.node_size)\n",
    "        self.H = np.random.randn(self.dim, self.feature_size)\n",
    "        \n",
    "        # Update\n",
    "        for i in range(20):\n",
    "            print('Iteration ', i)\n",
    "            # Update W\n",
    "            B = np.dot(self.H, self.T)\n",
    "            drv = 2 * np.dot(np.dot(B, B.T), self.W) - \\\n",
    "                2*np.dot(B, self.M.T) + self.lamb*self.W\n",
    "            Hess = 2*np.dot(B, B.T) + self.lamb*np.eye(self.dim)\n",
    "            drv = np.reshape(drv, [self.dim*self.node_size, 1])\n",
    "            rt = -drv\n",
    "            dt = rt\n",
    "            vecW = np.reshape(self.W, [self.dim*self.node_size, 1])\n",
    "            while np.linalg.norm(rt, 2) > 1e-4:\n",
    "                dtS = np.reshape(dt, (self.dim, self.node_size))\n",
    "                Hdt = np.reshape(np.dot(Hess, dtS), [\n",
    "                                 self.dim*self.node_size, 1])\n",
    "\n",
    "                at = np.dot(rt.T, rt)/np.dot(dt.T, Hdt)\n",
    "                vecW = vecW + at*dt\n",
    "                rtmp = rt\n",
    "                rt = rt - at*Hdt\n",
    "                bt = np.dot(rt.T, rt)/np.dot(rtmp.T, rtmp)\n",
    "                dt = rt + bt * dt\n",
    "            self.W = np.reshape(vecW, (self.dim, self.node_size))\n",
    "\n",
    "            # Update H\n",
    "            drv = np.dot((np.dot(np.dot(np.dot(self.W, self.W.T), self.H), self.T)\n",
    "                          - np.dot(self.W, self.M.T)), self.T.T) + self.lamb*self.H\n",
    "            drv = np.reshape(drv, (self.dim*self.feature_size, 1))\n",
    "            rt = -drv\n",
    "            dt = rt\n",
    "            vecH = np.reshape(self.H, (self.dim*self.feature_size, 1))\n",
    "            while np.linalg.norm(rt, 2) > 1e-4:\n",
    "                dtS = np.reshape(dt, (self.dim, self.feature_size))\n",
    "                Hdt = np.reshape(np.dot(np.dot(np.dot(self.W, self.W.T), dtS), np.dot(self.T, self.T.T))\n",
    "                                 + self.lamb*dtS, (self.dim*self.feature_size, 1))\n",
    "                at = np.dot(rt.T, rt)/np.dot(dt.T, Hdt)\n",
    "                vecH = vecH + at*dt\n",
    "                rtmp = rt\n",
    "                rt = rt - at*Hdt\n",
    "                bt = np.dot(rt.T, rt)/np.dot(rtmp.T, rtmp)\n",
    "                dt = rt + bt * dt\n",
    "            self.H = np.reshape(vecH, (self.dim, self.feature_size))\n",
    "        self.Vecs = np.hstack(\n",
    "            (normalize(self.W.T), normalize(np.dot(self.T.T, self.H.T))))\n",
    "        # get embeddings\n",
    "        self.vectors = {}\n",
    "        look_back = self.g.look_back_list\n",
    "        for i, embedding in enumerate(self.Vecs):\n",
    "            self.vectors[look_back[i]] = embedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import ast\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a68e202ca199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_node_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTADW\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrepresentation_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-947493de4d5a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, dim, lamb)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlamb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetAdj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-947493de4d5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAdj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[1;31m# M=(A+A^2)/2 where A is the row-normalized adjacency matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-947493de4d5a>\u001b[0m in \u001b[0;36mgetAdj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mnode_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mlook_up\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlook_up_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0madj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlook_up\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlook_up\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_auc = {}\n",
    "for split_part in np.arange(0.1, 0.2, 0.1):\n",
    "    g = Graph()\n",
    "    representation_size = 200\n",
    "    lamb = 0.2\n",
    "    \n",
    "    clf_ratio = np.round(split_part,2) \n",
    "\n",
    "    #filename = 'Foursquare/split_data/'+str(clf_ratio)+'_reorder_train.txt'\n",
    "    filename = 'Gowalla/split_data/'+str(clf_ratio)+'_reorder_train.txt'\n",
    "    g.read_adjlist(filename)\n",
    "\n",
    "    #feature_file = 'Foursquare/split_data/'+str(clf_ratio)+'_GMM_tadw_embed.txt'\n",
    "    feature_file = 'Gowalla/split_data/'+str(clf_ratio)+'_GMM_tadw_embed.txt'\n",
    "    g.read_node_features(feature_file)\n",
    "    \n",
    "    model = TADW( graph=g, dim=representation_size, lamb=lamb)\n",
    "    \n",
    "    \n",
    "#     filename = 'Foursquare/split_data/'+str(clf_ratio)+'_tadw_embed.txt'\n",
    "\n",
    "\n",
    "#     model.vectors = {}\n",
    "#     look_back = model.g.look_back_list\n",
    "#     for i, embedding in enumerate(model.Vecs):\n",
    "#         model.vectors[look_back[i]] = embedding\n",
    "\n",
    "#     fout = open(filename, 'w')\n",
    "#     for vkey in model.vectors.keys():\n",
    "\n",
    "#         fout.write(\"{}\\n\".format( ' '.join([str(i) for i in model.vectors[vkey]]) ))\n",
    "\n",
    "#     fout.close()    \n",
    "    \n",
    "    #filename = 'Foursquare/split_data/'+str(clf_ratio)+'_tadw_embed.txt'\n",
    "    filename = 'Gowalla/split_data/'+str(clf_ratio)+'_tadw_embed.txt'\n",
    "    fout = open(filename, 'w')\n",
    "    for vkey in model.vectors.keys():\n",
    "\n",
    "        fout.write(\"{} {}\\n\".format(vkey,  ' '.join([str(i) for i in model.vectors[vkey]]) ))\n",
    "\n",
    "    fout.close()  \n",
    "    \n",
    "    import random\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    random.seed(0)\n",
    "    node2vec = {}\n",
    "\n",
    "#     f = open('Foursquare/split_data/'+str(clf_ratio)+'_tadw_embed.txt', 'rb')\n",
    "#     for i, j in enumerate(f):\n",
    "#         if j.decode() != '\\n':\n",
    "#             node2vec[i] = list(map(float, j.strip().decode().split(' ')))\n",
    "            \n",
    "    #f = open('Foursquare/split_data/'+str(clf_ratio)+'_tadw_embed.txt', 'rb')\n",
    "    f = open('Gowalla/split_data/'+str(clf_ratio)+'_tadw_embed.txt', 'rb')\n",
    "    for i, j in enumerate(f):\n",
    "        if j.decode() != '\\n':\n",
    "            tmp = list(map(float, j.strip().decode().split(' ')))\n",
    "            node2vec[tmp[0]] = tmp[1:]\n",
    "\n",
    "    #f1 = open(os.path.join('Foursquare/split_data/'+str(clf_ratio)+'_reorder_test.txt'), 'rb')\n",
    "    f1 = open(os.path.join('Gowalla/split_data/'+str(clf_ratio)+'_reorder_test.txt'), 'rb')\n",
    "    edges = [list(map(int, i.strip().decode().split('\\t'))) for i in f1]\n",
    "    nodes = list(set([i for j in edges for i in j]))\n",
    "    a = 0\n",
    "    b = 0\n",
    "    for i, j in edges:\n",
    "        if i in node2vec.keys() and j in node2vec.keys():\n",
    "            dot1 = np.dot(node2vec[i], node2vec[j])\n",
    "            random_node = random.sample(nodes, 1)[0]\n",
    "            while random_node == j or random_node not in node2vec.keys():\n",
    "                random_node = random.sample(nodes, 1)[0]\n",
    "            dot2 = np.dot(node2vec[i], node2vec[random_node])\n",
    "            if dot1 > dot2:\n",
    "                a += 1\n",
    "            elif dot1 == dot2:\n",
    "                a += 0.5\n",
    "            b += 1\n",
    "\n",
    "    print(\"Auc value:\", float(a) / b)\n",
    "    total_auc[str(clf_ratio)] = float(a) / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gowalla\n",
    "print(total_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.1': 0.71549760157529, '0.2': 0.7354253736629596, '0.3': 0.7394830580823692, '0.4': 0.7448160391533937, '0.5': 0.7423084056298556, '0.6': 0.7361032404306836, '0.7': 0.7355623100303952}\n"
     ]
    }
   ],
   "source": [
    "# Forsquare\n",
    "print(total_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.7': 0.5000257585904899, '0.8': 0.7346350007727577, '0.9': 0.7222193601566123}\n"
     ]
    }
   ],
   "source": [
    "print(total_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
